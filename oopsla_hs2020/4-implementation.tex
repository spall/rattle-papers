\section{Implementing \Rattle}
\label{sec:implementation}

We have implemented the design from \S\ref{sec:design} in a build system called \Rattle. We use Haskell as the host language and to write the control logic. Copying the design for \Shake \cite{shake}, a \Rattle build script is a Haskell program that uses the \Rattle library.

\subsection{A \Rattle example}

\begin{figure}
  \begin{small}
    % I know this syntax is fake
\begin{verbatim}
import Development.Rattle
import System.FilePattern
import System.FilePath

main = rattle $ do
    cs <- liftIO $ getDirectoryFiles "." [root </> "*.c"]
    forP cs $ \c ->
        cmd "gcc -c" c
    let toO x = takeBaseName x <.> "o"
    cmd "gcc -o main.exe" (map toO cs)
\end{verbatim}
\end{small}
\caption{A Haskell/\Rattle version of the script from \S\ref{sec:monadic}}
\label{fig:rattle_example}
\end{figure}

\begin{figure}
\begin{small}
\begin{verbatim}
-- The Run monad                           -- Reading/writing files
data Run a = ...                           cmdReadFile :: FilePath -> Run String
rattle :: Run a -> IO a                    cmdWriteFile :: FilePath -> String -> Run ()

-- Running commands                        -- Parallelism
data CmdOption = Cwd FilePath | ...        forP :: [a] -> (a -> Run b) -> Run [b]
cmd :: CmdArguments args => args
\end{verbatim}
\end{small}
\caption{The \Rattle API}
\label{fig:api}
\end{figure}

A complete \Rattle script that compiles all \texttt{.c} files like \S\ref{sec:monadic} is given in Figure \ref{fig:rattle_example}, with the key API functions in Figure \ref{fig:api}. Looking at the example, we see:

\begin{itemize}
\item A \Rattle script is a Haskell program. It makes use of ordinary Haskell imports, and importantly uses \texttt{Development.Rattle}, offering the API from Figure \ref{fig:api}.
\item The \texttt{rattle} function takes a value in the \texttt{Run} monad and executes it in \texttt{IO}. The \texttt{Run} type is the \texttt{IO} monad, enriched with a \texttt{ReaderT} \cite{mtl} containing a reference to shared mutable state (e.g. which commands are in flight, where to store metadata, location of shared storage).
\item All the control logic is in Haskell and can use external libraries -- e.g. \texttt{System.FilePath} for manipulating \texttt{FilePath} values and \texttt{System.FilePattern} for directory listing. Taking the example of replacing the extension from \texttt{.c} to \texttt{.o}, we are able to abstract out this pattern as \texttt{toO} and reuse it later. Arbitrary Haskell IO can be embedded in the script using \texttt{liftIO}. All of the Haskell code (including the IO) is considered control logic and will be repeated in every execution.
\item Commands are given to the build system part of \Rattle using \texttt{cmd}. We have implemented \texttt{cmd} as a variadic function \cite{variadic_functions} which takes a command as a series of \texttt{String} (a series of space-separated arguments), \texttt{[String]} (a list of arguments) and \texttt{CmdOption} (command execution modifiers, e.g. to change the current directory), returning a value of type \texttt{Run ()}. The function \texttt{cmd} only returns once the command has finished executing (whether that is by actual execution, skipping, or fetching from external storage).
\item We have used \texttt{forP} in the example, as opposed to \texttt{forM}, which causes the commands to be given to \Rattle in parallel (\S\ref{sec:explicit_parallelism}). We could have equally used \texttt{forM} and relied on speculation for parallelism (\S\ref{sec:speculation}).
\end{itemize}

Looking at the functions from Figure \ref{fig:api}, there are two functions this example does not use. The \texttt{cmdWriteFile} and \texttt{cmdReadFile} functions are used to perform a read/write of the file system through Haskell code, causing hazards to arise if necessary. Apart from these functions, it is assumed that all Haskell control code only reads and writes files which are not written to by any commands.

For further examples of \Rattle programs see \S\ref{sec:eval:writing_rattle}.

\subsection{Alternative \Rattle wrappers}

Given the above API, combined with the choice to treat the control logic as opaque, it is possible to write wrappers that expose \Rattle in new ways. For example, to run a series of commands from a file, we can write:

\vspace{3mm}
\begin{small}
\begin{verbatim}
main = rattle $ do
    [x] <- liftIO getArgs
    src <- readFile x
    forM_ (lines src) cmd
\end{verbatim}
\end{small}
\vspace{3mm}

Here we take a command line argument, read the file it points to, then run each command sequentially using \texttt{forM\_}. We use this script for our evaluation in \S\ref{sec:evaluation}.

An alternative API could be provided by opening up a socket, and allowing a \Rattle server to take command invocations through that socket. Such an API would allow writing \Rattle scripts in other languages, making use of the existing \Rattle implementation. While such an implementation should be easy, we have not yet implemented it.

\subsection{Specific design choices and consequences}
\label{sec:choices}

Relative to the reference design in \S\ref{sec:design} we have made a few specific design choices, mostly in the name of implementation simplicity:

\begin{itemize}
\item All of our predictions (see \S\ref{sec:speculation}) only look at the very last run. This approach is simple, and in practice, seems to be sufficient -- most build scripts are run on very similar inputs most of the time.
\item We run a command speculatively if 1) it hasn't been run so far this build; 2) was required in the last run; and 3) doesn't cause a hazard relative to both the completed commands and predicted file accesses of the currently running commands. Importantly, if we are currently running a command we have never run before, we don't speculate anything -- the build system has changed in an unknown way so we take the cautious approach.
\item We never attempt to recover after speculation (see \S\ref{sec:recovering}), simply aborting the build and restarting without any speculation.
%% \item We have not yet implemented speculative-read-write hazards, and equally have not seen them occur. Under normal (non-adversarial) circumstances, given our cautious approach to speculation, we consider such hazards extremely unlikely.
\item We treat command lines as black boxes, never examining them to predict their outputs. For many programs a simple analysis (e.g. looking for \texttt{-o} flags) might be predictive.
\item \Rattle can go wrong if a speculated command writes to an input file, as per \S\ref{sec:proof:restart_no_speculation}. This problem hasn't occurred in practice, but dividing files into inputs and outputs would be perfectly reasonable. Typically the inputs are either checked into version control or outside the project directory, so that information is readily available.
\item It is important that traces (as stored for \S\ref{sec:skipping_unnecessary}) are only recorded to disk when we can be sure they were not affected by any hazards (see \S\ref{sec:proof:continue}). That determination requires waiting for all commands which ran at the same time as the command in question to have completed.
\item We model queries for information about a file (e.g. existence or modification time) as a read for tracing purposes, thus depending on the contents of the file. For queries about the existence of a file, we rerun if the file contents changes, which may be significantly more frequent than when the file is created or deleted. For queries about modification time, we don't rerun if the modification time changes but the file contents don't, potentially not changing when we should. In practice, most modification time queries are to implement rebuilding logic, so can be safely ignored if the file contents haven't changed.

\end{itemize}

\begin{comment}
\subsection{Hash forwarding}
\label{sec:forward_hashes}

One of the problems of non-deterministic builds is that they reduce external cache hits, as described in \S\ref{sec:cloud_builds}. As a concrete example, consider the build script:

\begin{small}
\begin{verbatim}
gcc -c main.c
gcc -o main.exe main.o
\end{verbatim}
\end{small}

Here we first compile \texttt{main.c} to produce \texttt{main.o}, then link \texttt{main.o} to produce \texttt{main.exe}. If we assume \texttt{gcc -c} is non-deterministic (e.g. embeds the current build time), and locally compile \texttt{gcc -c main.c}, then we will never get cache hits for the linking step. To avoid this problem, assuming all \texttt{main.o} values produced by the same \texttt{main.c} can be replaced for each other, we can use the hash of \texttt{main.c} to identify the output \texttt{main.o}.

\Rattle implements a more general version of this feature with the name ``hash forwarding''. If the output of a command produces files named \texttt{x} and \texttt{x.forward}, then the hash of \texttt{x.forward} is used to identify \texttt{x} instead of the hash of \texttt{x}. To modify the above example to take advantage of hash forwarding we can write:

\begin{verbatim}
gcc -c main.c && cp main.c main.o.forward
gcc -o main.exe main.o
\end{verbatim}

We require that if the ``important'' part of \texttt{main.o} changes then the file \texttt{main.o.forward} must also change. It would be equally possible to trim non-significant whitespace or comments from \texttt{main.c} to produce a more stable hash.

The disadvantage of hash forwarding (other than complexity) is that if the output file eliminates some information compared to the inputs, e.g. is simply the number of lines in the input, then there might be instances where two output values would be equal despite their forwarding hashes being different, causing fewer cache hits. The use of hash forwarding is very similar to the idea of deep-constructive traces from \citet[\S4.2.4]{build_systems_a_la_carte}, including the inability to benefit from unchanging outputs.
\end{comment}

\subsection{Storage and cloud storage}
\label{sec:cloud_implementation}

Our \Rattle implementation stores all information required between executions to disk. To provide reuse between multiple different users, we can store these artefacts on a shared drive, and then use tools such as NFS or Samba to provide remote connectivity and thus full ``cloud builds''. \Rattle stores three different types of information:

\begin{enumerate}
\item \textbf{Command traces} record which files were accessed when a specific command line (including environment variables etc.) was run. For each file accessed, we record whether it was read or written to, and the hash of the file. These traces are used to determine whether to skip running a command as per \S\ref{sec:skipping_unnecessary}, and are required to avoid continually rebuilding everything. These traces are each relatively small and there may be hundreds per run (one per command executed), meaning the cost to storing them is fairly low.
\item \textbf{Speculation traces} record which commands were required by the last run. If the speculation information is missing, \Rattle uses an empty speculation trace, and won't get any speculative parallelism as per \S\ref{sec:speculation}. There is only one speculation trace stored or queried per run, so the cost of these traces is very low.
\item \textbf{File contents} record mappings from file hashes to the complete files. These hashes are used in conjunction with the command traces to allow copying outputs if all the inputs match, as per \S\ref{sec:cloud_builds}. Given a local file system with cheap copy-on-write semantics, it would be fairly cheap to add entries to the the file contents mapping. Unfortunately, copy-on-write is not a standard feature of most file systems, so copying files to this storage can have approximately a 10\% performance cost.
\end{enumerate}

When speculation traces are shared between multiple users, who may be compiling different versions of the software, it is useful to index the speculation trace by commit reference, so that the nearest ancestor commit with speculation information can be used. Because speculation information is necessarily approximate, using slightly old speculation information is not harmful. However, in practice we currently store only the latest speculation information, and because \Rattle is currently used with only small numbers of users, this approach works sufficiently well (but would definitely not scale to more users). Addressing this limitation is on our roadmap, and should not be difficult.

When sharing storage between multiple untrusted users, it is important to consider security implications. The file contents store is indexed by hash, and checking the hash on retrieval ensures the integrity of the data (assuming a strong hash function). The command traces are fundamentally relied upon, so should only be written to be trusted users. The speculation traces aren't relied upon by the build system, but a malicious speculation trace could cause a user to execute a malicious command, so should also be written only by trusted users. We have not yet implemented any security restrictions.

\subsection{Tracing approaches}
\label{sec:tracing}

In \S\ref{sec:assume_tracing} we assume the existence of \emph{dependency tracing} which can, after a command completes, tell us which files that command read and wrote. Unfortunately, such an API is \emph{not} part of the POSIX standard, and is not easily available on any standard platform. We reuse the file access tracing features that have been added to \Shake \cite{neil:file_access}, which in turn are built on top of \Fsatrace \cite{fsatrace}. The techniques and limitations vary by OS:

\begin{itemize}
\item On \textbf{Linux} we use \texttt{LD\_LIBRARY\_PRELOAD} to inject a different C library into the process, which records file accesses, and then forwards functions on to the original C library. There are two main reasons we might fail to detect a file access. Firstly, the library we use (namely \Fsatrace) doesn't support all C library functions, as there are a great number which perform file accesses (e.g. in addition to the traditional \texttt{open}, there is also a newer \texttt{openat}). Fortunately, while it is difficult to determine the full C library file API, \Fsatrace has extensive coverage in practice, including at least 28 different file-related functions on Linux platforms.\footnote{Many of these functions appear to be entirely undocumented, and required reverse-engineering by the \Fsatrace developers.} Secondly, the program might not dynamically load the C library -- that is common in programs that invoke system calls directly (typically Go programs \cite{go}) or have their C library statically linked to the binary. In future we plan to integrate \Bigbro \cite{bigbro} as an alternative, which uses \texttt{ptrace} and doesn't rely on using a dynamic C library.
\item On \textbf{Mac} we also use \texttt{LD\_LIBRARY\_PRELOAD}. While the technique works on a Mac, from Mac OS X 1.10 onwards system binaries can't be traced due to System Integrity Protection\footnote{\url{https://developer.apple.com/library/content/documentation/Security/Conceptual/System_Integrity_Protection_Guide/ConfiguringSystemIntegrityProtection/ConfiguringSystemIntegrityProtection.html}}. As an example of a program this impacts, the C/C++ compiler is typically installed as a system binary. It is possible to disable System Integrity Protection (but not recommended by Apple); or to use non-system binaries (e.g. those supplied by \Nix \cite{nix}); or to copy the system binary to a temporary directory (which works provided the binary does not afterwards invoke another system binary). The library preload mechanism is implemented by \Fsatrace and the copying system binaries trick on Mac is implemented in \Shake.
\item On \textbf{Windows} it is possible to hook the Kernel API, which can be used to detect when any files are accessed. Since this hook is at the kernel level, all programs are subject to it, and while it is important to cover all entry points, that list of entry points is well documented and quite minimal, so easy to cover entirely. Implementing the hook is difficult, particularly around 32bit v 64bit differences, as custom assembly language trampolines must be used. Furthermore, some antivirus products (incorrectly) detect programs using the kernel hook as viruses. Windows kernel hooking is available in  \Fsatrace, although without support for 32bit processes that spawn 64bit processes. In practice this limitation is rarely a problem (most binaries are now 64bit), often easily remedied (switch to the 64bit version), and possible to fix in \Fsatrace if it was necessary (the engineering is difficult, but the technique is known and used by other tools).
\item On all platforms, \Fsatrace does not record access to directories (as opposed to files). Thus, if the kind of file-listing logic seen in \ref{fig:getdir} was moved into a binary that needed to be traced, changes to the directory itself (such as adding new files) would not trigger a reexecution of the relevant command.
\item On all platforms, any subcommands that are executed have their system accesses tracked and attributed to the parent process. As an example, \texttt{gcc} invokes \texttt{as} when compiling to transform textual assembly code to machine code. The tracing of \texttt{gcc} will include a read access to the \texttt{as} binary and a write to the \texttt{.o} file that \texttt{as} produces.
\item Files which are both written and deleted before the command completes are considered as temporary files. They are reported by \Fsatrace, but we ignore them in \Rattle. Examples of such files are the temporary textual assembly code produced by \texttt{gcc} to give to \texttt{as}, which is also written in a temporary directory with a random filename.
\end{itemize}

\noindent In practice, none of the limitations have been overly problematic in the examples we have explored.

The consequence of a tracing tool not reporting a file access would be failing to re-run a build command when the true dependencies change, or speculating a command when it shouldn't be. To take a concrete example, the gRPC generator (named \texttt{protoc}) is written in Go. If a \Rattle build features the command:

\begin{verbatim}
cmd "protoc hello.grpc --js_out=js"
\end{verbatim}

That reads the file \texttt{hello.proto}, and writes the file \texttt{js/hello.js}, but on Linux and Mac \Rattle does not know that. If the file \texttt{hello.proto} changes, \Rattle will fail to rebuild \texttt{js/hello.js} causing it to produce an \emph{incorrect result}. If the result is taken from a cloud cache (\S\ref{sec:cloud_builds}) it will not fetch \texttt{js/hello.js}. The dependency on the \texttt{protoc} binary itself \emph{is} tracked as that is done by the operating system.

To resolve the issue, it is necessary to explicitly tell \Rattle the dependencies, with:

\begin{verbatim}
cmd "protoc hello.grpc --js_out=js"
    (Read ["hello.grpc"]) (Write ["js/hello.js"])
\end{verbatim}

Unfortunately, it is not immediately obvious \emph{when} a tracing tool has returned incomplete dependencies, and manually specifying dependencies results in all the missing and incomplete dependency issues that are common in Makefile-based builds, which \Rattle was designed to avoid.

\vspace{2mm}



%\subsection{Possible Tracing Enhancements}

We designed \Rattle to work with the limitations of the best cross-platform tracing easily available -- but that involves trade-offs. An enhanced, portable system would be a significant enabler for \Rattle.
Our wishlist for tracing would include a cross-platform API, precise detection times, detection as access happens, and executing code at interception points.

%% \begin{itemize}
%% \item A standardised cross-platform API for tracing, implemented by the operating system itself, would vastly simplify the work required and guarantee robustness.
%% \item If we could detect exactly when files were opened and closed we could report fewer hazards, as currently we assume all files are open during the entire command.
%% \item If we could detect file accesses as they happened we could report hazards sooner, and avoid speculating on commands that are guaranteed to conflict with those currently running.
%% \item If we could reject file writes, we could eliminate most hazards from speculation by rejecting the speculative write that leads to a read-write or write-write hazard.
%% \item If we could redirect file writes, we could eliminate all hazards from speculation by sending such writes to a shared cache, not directly to the output files.
%% \end{itemize}

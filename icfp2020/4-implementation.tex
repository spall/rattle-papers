\section{Implementing \Rattle}
\label{sec:implementation}

The design of rattle assumes a stream of commands, as per \S\ref{sec:monadic}.

\Rattle assumes that each command is atomic - it cannot be subdivided into smaller parts. If a command is secretly two independent commands then they should usually be expressed as such so they can be individually skipped.

Compound commands: Sometimes a command will produce something that is user specific (not great for caching), but the next step will remove the user specificity (good for caching). To fix that we allow compound commands, by conjoining two commands with \texttt{\&\&}. Sometimes the sole purpose of the second command can be to strip machine-unique data from the first command.

\subsection{Forward rules}
\label{sec:forward_hashes}

Rattle has forward build rules to add determinism. then if a user is temporarily disconnected from the cloud storage, and try and build something, then it will result in a different hash. If the user then reconnects to the cloud all actions depending on that non-deterministic build will fail to get a cache hit. There is one solution in \Rattle, where the hash of an output can be considered to be the hash of its inputs, but this setting is enabled on a per-file basis, and has all the problems of deep-constructive traces from \cite{build_systems_a_la_carte} \S?? and cannot benefit from unchanging outputs.

We can write something that calls cmd on each element in a file. Or something that takes a socket, allowing programs to be written in Python for instance.

As another example, the GHC package database has additional entries added every time a package is installed, making the output a consequence of the original file\footnote{As a consequence many build systems, including \Bazel and \Rattle, use multiple package databases with only one entry per database}.

For our evaluation testbed, \Rattle, we choose to use Haskell as the host language, meaning that the control logic is in Haskell, with a special \texttt{cmd} function for informing the build system part about commands. The complete \Rattle script that compiles all \texttt{.c} files as per \S\ref{sec:monadic} is given in Figure \ref{fig:monadic}.

\begin{figure}
\begin{verbatim}
import Development.Rattle
import System.FilePath
import System.FilePattern

main = runRattle $ do
    let toO x = takeBaseName x <.> "o"
    cs <- liftIO $ getDirectoryFiles "." [root </> "*.c"]
    forM_ cs $ \c ->
        cmd "gcc -c" c
    cmd "gcc -o main.exe" (map toO cs)
\end{verbatim}
\caption{A Haskell/\Rattle version of the script from \S\ref{sec:monadic}}
\label{fig:monadic}
\end{figure}

\begin{figure}
\begin{verbatim}
-- key functions
data Run a = ... deriving (Functor, Applicative, Monad, MonadIO)
runRattle :: Run a -> IO a
data CmdOption = Cwd FilePath | ...
cmd :: CmdArguments args => args
cmdReadFile :: FilePath -> Run String
cmdWriteFile :: FilePath -> String -> Run ()

-- useful combinators
forP :: [a] -> (a -> Run b) -> Run [b]
memo :: (Eq a, Hashable a, MonadIO m) => (a -> m b) -> m (a -> m b)
\end{verbatim}
\caption{The \Rattle API}
\label{fig:api}
\end{figure}

The most important functions in the \Rattle API are shown in Figure \ref{fig:api}. The main type is \texttt{Run} which serves as a monad wrapping \texttt{IO} with the necessary state required, which can be executed by \texttt{runRattle}. The function \texttt{cmd} is a variadic function \cite{variadic_functions} which takes a command as a series of \texttt{String} (a series of space-separated arguments), \texttt{[String]} (a list of arguments) and \texttt{CmdOption} (command execution modifiers, e.g. to change the current directory), returning a value of type \texttt{Run ()}. In general, our model assumes that nothing else is concurrently modifying files, so the special functions \texttt{cmdReadFile} and \texttt{cmdWriteFile} are required to declare such operations.

\Rattle also ships with a series of useful combinators, e.g. an explicitly parallel mapping function (\texttt{forP}) and some memoisation operations (\texttt{memo}). However, these functions are merely useful helpers that are often required when writing build systems -- none of them interacts fundamentally with the build system. In the Haskell API for \Rattle there is a parallel combinator \texttt{forP}. Replacing \texttt{forM} with \texttt{forP} in Figure \ref{fig:monadic} causes the commands to be given to \Rattle in parallel. As a consequence, they can be executed in parallel. The use of explicit parallelism is convenient when replacing a loop, but harder when expressing that three executables can be built in parallel, but that a single shared object common to all of them must complete before starting, so it is difficult to provide \emph{complete} parallelism annotations.

In addition, most \Rattle programs make use of standard libraries such as \texttt{System.FilePath} for path manipulation, and \texttt{System.FilePattern} for matching files. The control logic is free to use any Haskell functions, provided they do not read/write files.

As a technical note, currently \Rattle uses a shared drive for sharing build artefacts, using tools such as NFS or Samba to provide the internet style ``cloud'' part.


\subsection{Tracing}
\label{sec:tracing}

In \S\ref{sec:assume_tracing} we assume the existence of \emph{dependency tracing} which can, after a command completes, tell us which files that command read and which files it wrote. Unfortunately, such an API is \emph{not} part of the POSIX standard, and is not easily available on any standard platform. We aim to make \Rattle work on Linux, Mac and Windows, which requires using a variety of approaches.

\subsubsection{Tracing approaches}

In this section we outline some of the approaches that can be used for tracing, their advantages and disadvantages:

\begin{description}
\item[Syscall tracing] On Linux you can trace every system call made, examine it's arguments, and thus record which files are accessed. Moreover, you can tell which have information about them queried (via the \texttt{stat} system call). The syscall tracking approach can be made complete, but because \emph{every} syscall must be hooked, can end up being a bit slow. This approach is used by \libbigbro \cite{libbigbro}.
\item[Library preload] On both Linux and Mac most programs refer to a dynamically linked C library for their file accesses. By using \texttt{LD\_LIBRARY\_PRELOAD} it is possible to inject another dynamic library into the program memory which intercepts the relevant C library calls, recording which files are read and written. This approach is simpler than hooking syscalls, but only works if all access to syscalls is made through the C library. For programs written in Go \cite{go}, the design is that the syscalls are invoked directly, meaning that nothing is observed by tracing the C library. For statically linked programs, the location of the C library is not available, and similarly they will not be traced. While the technique works on a Mac, from Mac OS X 1.10 or higher system binaries can't be traced due to System Integrity Protection\footnote{\url{https://developer.apple.com/library/content/documentation/Security/Conceptual/System_Integrity_Protection_Guide/ConfiguringSystemIntegrityProtection/ConfiguringSystemIntegrityProtection.html}}. As an example, the C compiler is typically installed as a system binary. It is possible to disable System Integrity Protection (but not recommended by Apple), to use non-system binaries (e.g. those supplied by \Nix \cite{nix} work well), or to copy the system binary to a temporary directory (which works provided the binary does not afterwards invoke another system binary to do its work). The library preload mechanism is implemented by \Fsatrace \cite{fsatrace} and the copying system binaries trick is implemented by \Shake \cite{shake}.
\item[File system tracing] An alternative approach on Linux would be to implement a file system that reported which files were accessed. We are aware of one such implementation, \tracedfs \cite{tracedfs}, which is unfortunately not yet complete. Such an approach would track all accesses, but may require privileges to mount a file system.
\item[Custom Mac tracing] \BuildXL \cite{buildxl}\footnote{\url{https://github.com/Microsoft/BuildXL/blob/master/Documentation/Specs/Sandboxing.md\#macos-sandboxing}} uses a Mac sandbox based on KAuth combined with TrustedBSD Mandatory Access Control (MAC) to both detect which files are accessed and also block access to specific files. The approach is based on internal Mac OS X detils which have been reversed engineered, some of which are deprecated and scheduled for removal.
\item[Windows Kernel API hooking] On Windows it is possible to hook the Kernel API, which can be used to detect when files are accessed. Hooking the kernel detects everything, but is not trivial. In particular, 32bit v 64bit differences are problematic, as Windows trampolines between the two and the hooks must cope with the differences using assembly code. Furthermore, some antivirus products are more likely to (incorrectly) detect such programs as viruses. The Windows kernel hooking is available in both \Fsatrace and \libbigbro, although without the 32bit calling 64bit assembly code.
\end{description}

\Rattle currently uses \Fsatrace as wrapped by \Shake for tracing. That means it uses library preloading on Linux/Mac and kernel hooking on Windows. The biggest limitations in practice vary by OS:

\begin{itemize}
\item On \textbf{Linux} it can't trace into Go programs and statically linked binaries. We are planning to integrate \libbigbro as an alternative, to address these concerns.
\item On \textbf{Mac} it can't trace into system binaries called from other system binaries. We recommend using \Nix binaries if this limitation is problematic.
\item On \textbf{Windows} it can't trace into 64bit programs invoked by 32bit programs. In most cases the 32bit binaries can easily be replaced by 64bit binaries. The only instance we've seen thus far was an outdated version of \texttt{sh} one of the authors of this paper downloaded over five years ago, which was easily remedied with a newer version.
\end{itemize}

However, in practice, none of the limitations have been overly problematic in the examples we have explored.

\subsubsection{Possible tracing enhancements}

Using the approaches listed above we are able to detect when files are opened for read or write access. After the command has finished, we then report which files were accessed and in what mode. That restricted interface has driven the design of \Rattle to ensure that it is possible to implement \Rattle robustly in realistic situations. However, there are places where a more refined interface would be useful.

Tracing file accesses is the most important file system information, but there is other information about a file a command may query -- for example the existence of a file or its modification time and size. We model these as reads of a file, with all the associated read/write hazard detection. % SS I am confused by the following line; the bit about being a proxy for incremental building is confusing.
We don't rerun if a file has changed modification time as we suspect it likely that modification time is used as a proxy for incremental building, which \Rattle already does. By virtue of \Rattle storing the hash and using it to determine if a file has changed, a size change is going to cause a rebuild. For the existence test, as a consequence of treating it as a read, \Rattle will rebuild slightly too much since the dependency is now on the entire contents rather than just the existence.  \Rattle also has to deal with files that are read but don't exist.

% SS elaborate what it means for rattle to deal with files that don't exist.  I'm assuming this just mean doing things like trying to get modtime/hash for files that don't exist etc.


The current mechanisms provide information about which files were accessed at the end. If they could interactively stream back which files were read, it would lead to better guesses in speculation (see \S\ref{sec:speculation}) about what files had been accessed by running system commands. With the tracing mechanisms available, there is no reason they couldn't report on which files had been read at any point via a socket, but such engineering work has not been done.

The approaches only report whether a file was accessed or not -- not at what time the access occurred. With a precise time it would be possible to have a more refined notion of hazard when commands are run in parallel. However, assuming commands are relatively short and that generally commands should not be relying on race conditions to avoid hazards, we consider the current approach quite reasonable. The enhancement could be implemented if desired.

It would be nice if the accesses could be intercepted and denied if there was a hazard violation, but that would require two way communication from the tracing to \Rattle. In many of the contexts being called (e.g. kernel tracing or syscall hooking) such communication is problematic, so while useful, we don't have it.

Finally, it would be useful to know the purpose of a file system access, but that is generally not available to the tracing system. As an example, many programs create, use and then delete temporary files. If multiple programs are run in a single \Rattle build then it is not unreasonable (and in fact, somewhat common) to see them access the \emph{same} temporary file, but distinct instances of it, which should not be reported as a hazard despite multiple writes. We solve such issues by ignoring reads and writes to the temporary directory.

\subsubsection{Tracing standardisation}

The tracing pieces of \Rattle have been some of the most difficult engineering pieces to develop. We suggest that such features should be standardised and made available in a cross-platform way.

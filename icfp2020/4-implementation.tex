\section{Implementing \Rattle}
\label{sec:implementation}

We have implemented the design from \S\ref{sec:design} in a program called \Rattle. We use Haskell as the host language, meaning that the control logic is in Haskell.

\subsection{A \Rattle example}

\begin{figure}
\begin{verbatim}
import Development.Rattle
import System.FilePath
import System.FilePattern

main = rattle $ do
    let toO x = takeBaseName x <.> "o"
    cs <- liftIO $ getDirectoryFiles "." [root </> "*.c"]
    forP cs $ \c ->
        cmd "gcc -c" c
    cmd "gcc -o main.exe" (map toO cs)
\end{verbatim}
\caption{A Haskell/\Rattle version of the script from \S\ref{sec:monadic}}
\label{fig:rattle_example}
\end{figure}

\begin{figure}
\begin{verbatim}
-- The Run monad
data Run a = ... deriving (Functor, Applicative, Monad, MonadIO)
rattle :: Run a -> IO a

-- Running commands
data CmdOption = Cwd FilePath | ...
cmd :: CmdArguments args => args

-- Reading/writing files
cmdReadFile :: FilePath -> Run String
cmdWriteFile :: FilePath -> String -> Run ()

-- Parallelism
forP :: [a] -> (a -> Run b) -> Run [b]
\end{verbatim}
\caption{The \Rattle API}
\label{fig:api}
\end{figure}

A complete \Rattle script that compiles all \texttt{.c} files as per \S\ref{sec:monadic} is given in Figure \ref{fig:rattle_example}, with the key API functions in Figure \ref{fig:api}. Looking at the example, we see:

\begin{itemize}
\item A \Rattle script is a Haskell program. It makes use of ordinary Haskell imports, and importantly includes \texttt{Development.Rattle} offering the API from Figure \ref{fig:api}.
\item The \texttt{rattle} function takes a value the \texttt{Run} monad and executes it in \texttt{IO}. The \texttt{Run} type is the \texttt{IO} monad, enriched with a \texttt{ReaderT} containing a reference to shared mutable state (e.g. what commands are in flight, where to store metadata, location of shared storage).
\item All the control logic is in Haskell and may make use of any external libraries -- e.g. \texttt{System.FilePath} for manipulating \texttt{FilePath} values and \texttt{System.FilePattern} for directory listing. Taking the example of replacing the extension from \texttt{.c} to \texttt{.o}, we are able to abstract out this pattern as \texttt{toO} and reuse it later. Abitrary Haskell IO can be embedded in the script using \texttt{liftIO}. All of the Haskell code is considered control logic and will be repeated in every execution.
\item Commands are given to the build system part of rattle using the \texttt{cmd}. We have implemented \texttt{cmd} as a variadic function \cite{variadic_functions} which takes a command as a series of \texttt{String} (a series of space-separated arguments), \texttt{[String]} (a list of arguments) and \texttt{CmdOption} (command execution modifiers, e.g. to change the current directory), returning a value of type \texttt{Run ()}. The function \texttt{cmd} only returns once the command has finished executing (whether that is by actual execution, skipping, or fetching from external storage).
\item We have used \texttt{forP} in the example, as opposed to \texttt{forM}, which causes the commands to be given to \Rattle in parallel. The use of explicit parallelism for distinct elements of a list is convenient.
\end{itemize}

Looking at the functions from Figure \ref{fig:api} there are two functions this example does not use. The \texttt{cmdWriteFile} and \texttt{cmdReadFile} are used to perform a read/write of the file system through Haskell code, causing hazards to arise if necessary. Apart from these functions, it is assumed that all Haskell control code only reads and writes files which are not involved in any commands.

\subsection{Alternative \Rattle wrappers}

Given the above API, combined with the choice to treat the control logic as opaque, it is possible to write wrappers that expose \Rattle in new ways. For example, to literally run a series of commands, it is possible to write use the \Rattle program:

\vspace{3mm}
\begin{verbatim}
main = rattle $ do
    [x] <- liftIO getArgs
    src <- readFile x
    forM_ (lines src) cmd
\end{verbatim}
\vspace{3mm}

Here we get single command line argument, read it as a file, then run each command sequentially using \texttt{forM\_}. We use this script in our evaluation in \S\ref{sec:evaluation}.

An alternative API could be provided by openning up a socket, and allowing a \Rattle server to take command invocations through that socket. Such an API would allow writting \Rattle scripts in other languages, making use of the existing \Rattle implementation. While such a design should be easy, we have not actually implemented it yet.

\subsection{Hash forwarding}
\label{sec:forward_hashes}

To cope with the problem of non-deterministic build results reducing external cache hits, as described in \S\ref{sec:cloud_builds}, \Rattle uses hash forwarding. If the output of a command produces a file \texttt{foo}, and also a file \texttt{foo.forward}, then the hash of \texttt{foo.forward} is used instead of the hash of \texttt{foo}. Provided \texttt{foo.forward} includes all information that \texttt{foo} depends on (or a hash thereof), then the forwarding hash can be treated as a proxy for the non-deterministic file. Moreover, since the most common forwarding is to take the hash of all inputs to the command, that feature is available through the \texttt{CmdOption} named \texttt{Forward}.

The disadvantage of hash forwarding (other than the complexity) is that if the resulting \texttt{foo} eliminates some information compared to the inputs, then there might be instances when two \texttt{foo} values would be equal despite their forwarding hashes being different, causing fewer cache hits. The use of hash forwarding is very similar to the idea of deep-constructive traces from \citet{build_systems_a_la_carte} \S4.2.4, including the inability to benefit from unchanging outputs.

\subsection{Specific design choices}

Relative to the reference design in \S\ref{sec:design} we have made a few specific design choices, mostly in the name of implementation simplicity:

\begin{itemize}
\item All our predictions (see \S\ref{sec:speculation}) only look at the very last run. This approach is simple, and in practice, seems to be sufficient -- most build scripts are run on very similar inputs most of the time.
\item We currently use a shared drive for sharing build artefacts, allow the use of tools such as NFS or Samba to provide remote connectivity and thus full ``cloud builds''.
\end{itemize}

Say how we chose what to speculate. A 5 point plan - find something that doesn't hazard out.


\subsection{Tracing approaches}
\label{sec:tracing}

In \S\ref{sec:assume_tracing} we assume the existence of \emph{dependency tracing} which can, after a command completes, tell us which files that command read and which files it wrote. Unfortunately, such an API is \emph{not} part of the POSIX standard, and is not easily available on any standard platform. We aim to make \Rattle work on Linux, Mac and Windows, which requires using a variety of approaches. In this section we outline some of the approaches that can be used for tracing, their advantages and disadvantages:

\begin{description}
\item[Syscall tracing] On Linux you can trace every system call made, examine it's arguments, and thus record which files are accessed. Moreover, you can tell which have information about them queried (via the \texttt{stat} system call). The syscall tracking approach can be made complete, but because \emph{every} syscall must be hooked, can end up being a bit slow. This approach is used by \libbigbro \cite{bigbro}.
\item[Library preload] On both Linux and Mac most programs refer to a dynamically linked C library for their file accesses. By using \texttt{LD\_LIBRARY\_PRELOAD} it is possible to inject another dynamic library into the program memory which intercepts the relevant C library calls, recording which files are read and written. This approach is simpler than hooking syscalls, but only works if all access to syscalls is made through the C library. For programs written in Go \cite{go}, the design is that the syscalls are invoked directly, meaning that nothing is observed by tracing the C library. For statically linked programs, the location of the C library is not available, and similarly they will not be traced. While the technique works on a Mac, from Mac OS X 1.10 or higher system binaries can't be traced due to System Integrity Protection\footnote{\url{https://developer.apple.com/library/content/documentation/Security/Conceptual/System_Integrity_Protection_Guide/ConfiguringSystemIntegrityProtection/ConfiguringSystemIntegrityProtection.html}}. As an example, the C compiler is typically installed as a system binary. It is possible to disable System Integrity Protection (but not recommended by Apple), to use non-system binaries (e.g. those supplied by \Nix \cite{nix} work well), or to copy the system binary to a temporary directory (which works provided the binary does not afterwards invoke another system binary to do its work). The library preload mechanism is implemented by \Fsatrace \cite{fsatrace} and the copying system binaries trick is implemented by \Shake \cite{shake}.
\item[File system tracing] An alternative approach on Linux would be to implement a file system that reported which files were accessed. We are aware of one such implementation, \tracedfs \cite{tracedfs}, which is unfortunately not yet complete. Such an approach would track all accesses, but may require privileges to mount a file system.
\item[Custom Mac tracing] \BuildXL \cite{buildxl}\footnote{\url{https://github.com/Microsoft/BuildXL/blob/master/Documentation/Specs/Sandboxing.md\#macos-sandboxing}} uses a Mac sandbox based on KAuth combined with TrustedBSD Mandatory Access Control (MAC) to both detect which files are accessed and also block access to specific files. The approach is based on internal Mac OS X detils which have been reversed engineered, some of which are deprecated and scheduled for removal.
\item[Windows Kernel API hooking] On Windows it is possible to hook the Kernel API, which can be used to detect when files are accessed. Hooking the kernel detects everything, but is not trivial. In particular, 32bit v 64bit differences are problematic, as Windows trampolines between the two and the hooks must cope with the differences using assembly code. Furthermore, some antivirus products are more likely to (incorrectly) detect such programs as viruses. The Windows kernel hooking is available in both \Fsatrace and \libbigbro, although without the 32bit calling 64bit assembly code.
\end{description}

\Rattle currently uses \Fsatrace as wrapped by \Shake for tracing. That means it uses library preloading on Linux/Mac and kernel hooking on Windows. The biggest limitations in practice vary by OS:

\begin{itemize}
\item On \textbf{Linux} it can't trace into Go programs and statically linked binaries. We are planning to integrate \libbigbro as an alternative, to address these concerns.
\item On \textbf{Mac} it can't trace into system binaries called from other system binaries. We recommend using \Nix binaries if this limitation is problematic.
\item On \textbf{Windows} it can't trace into 64bit programs invoked by 32bit programs. In most cases the 32bit binaries can easily be replaced by 64bit binaries. The only instance we've seen thus far was an outdated version of \texttt{sh} one of the authors of this paper downloaded over five years ago, which was easily remedied with a newer version.
\end{itemize}

However, in practice, none of the limitations have been overly problematic in the examples we have explored.

\subsection{Possible Tracing Enhancements}

Using the approaches listed above we are able to detect when files are opened for read or write access. After the command has finished, we then report which files were accessed and in what mode. That restricted interface has driven the design of \Rattle to ensure that it is possible to implement \Rattle robustly in realistic situations. However, there are places where a more refined interface would be useful.

Tracing file accesses is the most important file system information, but there is other information about a file a command may query -- for example the existence of a file or its modification time and size. We model these as reads of a file, with all the associated read/write hazard detection. % SS I am confused by the following line; the bit about being a proxy for incremental building is confusing.
We don't rerun if a file has changed modification time as we suspect it likely that modification time is used as a proxy for incremental building, which \Rattle already does. By virtue of \Rattle storing the hash and using it to determine if a file has changed, a size change is going to cause a rebuild. For the existence test, as a consequence of treating it as a read, \Rattle will rebuild slightly too much since the dependency is now on the entire contents rather than just the existence.  \Rattle also has to deal with files that are read but don't exist.

% SS elaborate what it means for rattle to deal with files that don't exist.  I'm assuming this just mean doing things like trying to get modtime/hash for files that don't exist etc.


The current mechanisms provide information about which files were accessed at the end. If they could interactively stream back which files were read, it would lead to better guesses in speculation (see \S\ref{sec:speculation}) about what files had been accessed by running system commands. With the tracing mechanisms available, there is no reason they couldn't report on which files had been read at any point via a socket, but such engineering work has not been done.

The approaches only report whether a file was accessed or not -- not at what time the access occurred. With a precise time it would be possible to have a more refined notion of hazard when commands are run in parallel. However, assuming commands are relatively short and that generally commands should not be relying on race conditions to avoid hazards, we consider the current approach quite reasonable. The enhancement could be implemented if desired.

It would be nice if the accesses could be intercepted and denied if there was a hazard violation, but that would require two way communication from the tracing to \Rattle. In many of the contexts being called (e.g. kernel tracing or syscall hooking) such communication is problematic, so while useful, we don't have it.

Finally, it would be useful to know the purpose of a file system access, but that is generally not available to the tracing system. As an example, many programs create, use and then delete temporary files. If multiple programs are run in a single \Rattle build then it is not unreasonable (and in fact, somewhat common) to see them access the \emph{same} temporary file, but distinct instances of it, which should not be reported as a hazard despite multiple writes. We solve such issues by ignoring reads and writes to the temporary directory.

Howver, most of all, standardisation would be fantastic. The tracing pieces of \Rattle have been some of the most difficult engineering pieces to develop. We suggest that such features should be standardised and made available in a cross-platform way.

NOTE: There are lots of issues around things like deleting, renaming files and directories which don't track as well as they should.

\section{Implementing \Rattle}
\label{sec:implementation}

We have implemented the design from \S\ref{sec:design} in a build system called \Rattle. We use Haskell as the host language and to write the control logic. Copying the design for \Shake \cite{shake}, a \Rattle build script is a Haskell program that uses the \Rattle library.

\subsection{A \Rattle example}

\begin{figure}
\begin{small}
\begin{verbatim}
import Development.Rattle
import System.FilePath
import System.FilePattern

main = rattle $ do
    let toO x = takeBaseName x <.> "o"
    cs <- liftIO $ getDirectoryFiles "." [root </> "*.c"]
    forP cs $ \c ->
        cmd "gcc -c" c
    cmd "gcc -o main.exe" (map toO cs)
\end{verbatim}
\end{small}
\caption{A Haskell/\Rattle version of the script from \S\ref{sec:monadic}}
\label{fig:rattle_example}
\end{figure}

\begin{figure}
\begin{small}
\begin{verbatim}
-- The Run monad
data Run a = ... deriving (Functor, Applicative, Monad, MonadIO)
rattle :: Run a -> IO a

-- Running commands
data CmdOption = Cwd FilePath | ...
cmd :: CmdArguments args => args

-- Reading/writing files
cmdReadFile :: FilePath -> Run String
cmdWriteFile :: FilePath -> String -> Run ()

-- Parallelism
forP :: [a] -> (a -> Run b) -> Run [b]
\end{verbatim}
\end{small}
\caption{The \Rattle API}
\label{fig:api}
\end{figure}

A complete \Rattle script that compiles all \texttt{.c} files like \S\ref{sec:monadic} is given in Figure \ref{fig:rattle_example}, with the key API functions in Figure \ref{fig:api}. Looking at the example, we see:

\begin{itemize}
\item A \Rattle script is a Haskell program. It makes use of ordinary Haskell imports, and importantly includes \texttt{Development.Rattle}, offering the API from Figure \ref{fig:api}.
\item The \texttt{rattle} function takes a value in the \texttt{Run} monad and executes it in \texttt{IO}. The \texttt{Run} type is the \texttt{IO} monad, enriched with a \texttt{ReaderT} \cite{mtl} containing a reference to shared mutable state (e.g. what commands are in flight, where to store metadata, location of shared storage).
\item All the control logic is in Haskell and can use external libraries -- e.g. \texttt{System.FilePath} for manipulating \texttt{FilePath} values and \texttt{System.FilePattern} for directory listing. Taking the example of replacing the extension from \texttt{.c} to \texttt{.o}, we are able to abstract out this pattern as \texttt{toO} and reuse it later. Arbitrary Haskell IO can be embedded in the script using \texttt{liftIO}. All of the Haskell code is considered control logic and will be repeated in every execution.
\item Commands are given to the build system part of \Rattle using \texttt{cmd}. We have implemented \texttt{cmd} as a variadic function \cite{variadic_functions} which takes a command as a series of \texttt{String} (a series of space-separated arguments), \texttt{[String]} (a list of arguments) and \texttt{CmdOption} (command execution modifiers, e.g. to change the current directory), returning a value of type \texttt{Run ()}. The function \texttt{cmd} only returns once the command has finished executing (whether that is by actual execution, skipping, or fetching from external storage).
\item We have used \texttt{forP} in the example, as opposed to \texttt{forM}, which causes the commands to be given to \Rattle in parallel (\S\ref{sec:explicit_parallelism}). We could have equally used \texttt{forM} and relied on speculation for parallelism (\S\ref{sec:speculation}).
\end{itemize}

Looking at the functions from Figure \ref{fig:api}, there are two functions this example does not use. The \texttt{cmdWriteFile} and \texttt{cmdReadFile} functions are used to perform a read/write of the file system through Haskell code, causing hazards to arise if necessary. Apart from these functions, it is assumed that all Haskell control code only reads and writes files which are not written to by any commands.

\subsection{Alternative \Rattle wrappers}

Given the above API, combined with the choice to treat the control logic as opaque, it is possible to write wrappers that expose \Rattle in new ways. For example, to run a series of commands from a file, we can write:

\vspace{3mm}
\begin{small}
\begin{verbatim}
main = rattle $ do
    [x] <- liftIO getArgs
    src <- readFile x
    forM_ (lines src) cmd
\end{verbatim}
\end{small}
\vspace{3mm}

Here we take a command line argument, read the file it points to, then run each command sequentially using \texttt{forM\_}. We use this script for our evaluation in \S\ref{sec:evaluation}.

An alternative API could be provided by opening up a socket, and allowing a \Rattle server to take command invocations through that socket. Such an API would allow writing \Rattle scripts in other languages, making use of the existing \Rattle implementation. While such an implementation should be easy, we have not yet actually implemented it.

\subsection{Specific design choices and consequences}
\label{sec:choices}

Relative to the reference design in \S\ref{sec:design} we have made a few specific design choices, mostly in the name of implementation simplicity:

\begin{itemize}
\item All of our predictions (see \S\ref{sec:speculation}) only look at the very last run. This approach is simple, and in practice, seems to be sufficient -- most build scripts are run on very similar inputs most of the time.
\item We run a command speculatively if 1) it hasn't been run so far this build; 2) was required in the last run; and 3) doesn't cause a hazard relative to both the completed commands and predicted file accesses of the currently running commands. Importantly, if we are currently running a command we have never run before, we don't speculate anything -- the build system has changed in an unknown way so we take the cautious approach.
\item We never attempt to recover after speculation (see \S\ref{sec:recovering}), simply aborting the build and restarting without any speculation.
\item We have not yet implemented speculative-read-write hazards, and equally have not seen them occur. Under normal (non-adversarial) circumstances, given our cautious approach to speculation, we consider such hazards extremely unlikely.
\item We treat command lines as black boxes, never examining them to predict their outputs. For many programs a simple analysis (e.g. looking for \texttt{-o} flags) might be predictive.
\item We use a shared drive for sharing build artefacts, but allow the use of tools such as NFS or Samba to provide remote connectivity and thus full ``cloud builds''.
\item \Rattle can go wrong if a speculated command writes to an input file, as per \S\ref{sec:proof:restart_no_speculation}. This problem hasn't occurred in practice, but dividing files into inputs and outputs would be perfectly reasonable -- typically the inputs are either checked into version control or outside the project directory, so that information is readily available.
\item It is important that traces (as stored for \S\ref{sec:skipping_unnecessary}) are only recorded to disk when we can be sure they were not poisoned (see \S\ref{sec:proof:continue}) by any hazards. That determination requires waiting for all commands which ran at the same time as the command in question to have finished.
\item We model queries for information about a file (e.g. existence or modification time) as a read for tracing purposes, thus depending on the contents of the file. For queries about the existence of a file, we rerun if the file contents changes, which may be significantly more frequent than when the file is created or deleted. For queries about modification time, we don't rerun if the modification time changes but the file contents don't, potentially not changing when we should. In practice, most modification time queries are to implement rebuilding logic, so can be safely ignored if the file contents haven't changed.
\end{itemize}


\subsection{Hash forwarding}
\label{sec:forward_hashes}

One of the problems of non-deterministic builds is that they reduce external cache hits, as described in \S\ref{sec:cloud_builds}. As a concrete example, assuming we have the build script:

\begin{small}
\begin{verbatim}
gcc -c main.c
gcc -o main.exe main.o
\end{verbatim}
\end{small}

Here we first compile \texttt{main.c} to produce \texttt{main.o}, then link \texttt{main.o} to produce \texttt{main.exe}. If we assume \texttt{gcc -c} is non-deterministic (e.g. embeds the current build time), and locally compile \texttt{gcc -c main.c}, then we will never get cache hits for the linking step. To avoid this problem, assuming all \texttt{main.o} values produced by the same \texttt{main.c} can be replaced for each other, we can use the hash of \texttt{main.c} to identify the output \texttt{main.o}.

\Rattle implements a more general version of this feature with the name ``hash forwarding''. If the output of a command produces files named \texttt{x} and \texttt{x.forward}, then the hash of \texttt{x.forward} is used to identify \texttt{x} instead of the hash of \texttt{x}. To modify the above example to take advantage of hash forwarding we can write:

\begin{verbatim}
gcc -c main.c && cp main.c main.o.forward
gcc -o main.exe main.o
\end{verbatim}

We require that if the ``important'' part of \texttt{main.o} changes then the file \texttt{main.o.forward} must also change. It would be equally possible to trim non-significant whitespace or comments from \texttt{main.c} to produce a more stable hash.

The disadvantage of hash forwarding (other than the complexity) is that if the output file eliminates some information compared to the inputs, e.g. is simply the number of lines in the input, then there might be instances where two output values would be equal despite their forwarding hashes being different, causing fewer cache hits. The use of hash forwarding is very similar to the idea of deep-constructive traces from \citet[\S4.2.4]{build_systems_a_la_carte}, including the inability to benefit from unchanging outputs.


\subsection{Tracing approaches}
\label{sec:tracing}

In \S\ref{sec:assume_tracing} we assume the existence of \emph{dependency tracing} which can, after a command completes, tell us which files that command read and wrote. Unfortunately, such an API is \emph{not} part of the POSIX standard, and is not easily available on any standard platform. We aim to make \Rattle work on Linux, Mac and Windows, which requires using a variety of approaches. In this section we outline some of the approaches that can be used for tracing, along with their advantages and disadvantages.

\paragraph{Syscall tracing} On Linux, \texttt{ptrace} allows tracing every system call made, examining the arguments, and thus recording the files accessed. Moreover, by tracing  the \texttt{stat} system call even file queries can be recorded. The syscall tracking approach can be made complete, but because \emph{every} syscall must be hooked, can end up imposing high overhead. This approach is used by \Bigbro \cite{bigbro} as well as numerous other debugging and instrumentation tools.

\paragraph{Library preload} On both Linux and Mac most programs use a dynamically linked C library to make file accesses. By using \texttt{LD\_LIBRARY\_PRELOAD} it is possible to inject a different library into the program memory which intercepts the relevant C library calls, recording which files are read and written. This approach is simpler than hooking syscalls, but only works if all syscall access is made through the C library. While normally true, that isn't the case for Go programs \cite{go} (syscalls are invoked directly) or statically linked programs (the C library cannot be replaced).

While the technique works on a Mac, from Mac OS X 1.10 onwards system binaries can't be traced due to System Integrity Protection\footnote{\url{https://developer.apple.com/library/content/documentation/Security/Conceptual/System_Integrity_Protection_Guide/ConfiguringSystemIntegrityProtection/ConfiguringSystemIntegrityProtection.html}}. As an example, the C compiler is typically installed as a system binary. It is possible to disable System Integrity Protection (but not recommended by Apple), to use non-system binaries (e.g. those supplied by \Nix \cite{nix}), or to copy the system binary to a temporary directory (which works provided the binary does not afterwards invoke another system binary to do its work). The library preload mechanism is implemented by \Fsatrace \cite{fsatrace} and the copying system binaries trick on Mac is implemented by \Shake \cite{shake}.

\paragraph{File system tracing} An alternative approach is to implement a custom file system and have that report which files are accessed. One such implementation for Linux is \tracedfs \cite{tracedfs}, which is unfortunately not yet complete. Such an approach can track all accesses, but may require administrator privileges to mount a file system.

\paragraph{Custom Mac tracing} \BuildXL \cite{buildxl}\footnote{\url{https://github.com/Microsoft/BuildXL/blob/master/Documentation/Specs/Sandboxing.md\#macos-sandboxing}} uses a Mac sandbox based on KAuth combined with TrustedBSD Mandatory Access Control (MAC) to both detect which files are accessed and also block access to specific files. The approach is based on internal Mac OS X details which have been reversed engineered, some of which are deprecated and scheduled for removal.

\paragraph{Windows Kernel API hooking} On Windows it is possible to hook the Kernel API, which can be used to detect when any files are accessed. Implementing such a hook is difficult, particularly around 32bit v 64bit differences, as custom assembly language trampolines must be used. Furthermore, some antivirus products (incorrectly) detect such programs as viruses. Windows kernel hooking is available in both \Fsatrace and \Bigbro, although without support for 32bit processes that spawn 64bit processes.

\postparagraphs

\Rattle currently uses \Fsatrace for the underlying tracing, with a Haskell interface provided by \Shake. That means it uses library preloading on Linux/Mac and kernel hooking on Windows. The biggest practical limitations vary by OS:

\begin{itemize}
\item On \textbf{Linux} it can't trace into Go programs (or other programs that use system calls directly) and statically linked binaries. We plan to integrate \Bigbro as an alternative, to address these concerns.
\item On \textbf{Mac} it can't trace into system binaries called from other system binaries. We recommend using \Nix binaries if this limitation is problematic.
\item On \textbf{Windows} it can't trace 64bit programs spawned by 32bit programs. In most cases the 32bit binaries can easily be replaced by 64bit binaries. The only problem we've seen was caused by a five year-old version of \texttt{sh}, which was easily remedied with a newer version.
\end{itemize}

\noindent In practice, none of the limitations have been overly problematic in the examples we have explored.

%\subsection{Possible Tracing Enhancements}

We designed \Rattle to work with the limitations of the best cross-platform tracing easily available -- but that involves trade-offs. An enhanced, portable system would be a significnat enabler for \Rattle.
Our wishlist for tracing would include a cross-platform API, precise detection times, detection as access happens, and executing code at interception points.

%% \begin{itemize}
%% \item A standardised cross-platform API for tracing, implemented by the operating system itself, would vastly simplify the work required and guarantee robustness.
%% \item If we could detect exactly when files were opened and closed we could report fewer hazards, as currently we assume all files are open during the entire command.
%% \item If we could detect file accesses as they happened we could report hazards sooner, and avoid speculating on commands that are guaranteed to conflict with those currently running.
%% \item If we could reject file writes, we could eliminate most hazards from speculation by rejecting the speculative write that leads to a read-write or write-write hazard.
%% \item If we could redirect file writes, we could eliminate all hazards from speculation by sending such writes to a shared cache, not directly to the output files.
%% \end{itemize}

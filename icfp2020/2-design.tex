\section{Build Scripts from Commands}
\label{sec:design}

Our goal is to design a build system where a build script is simply a list of commands. In this section we develop our design, starting with the simplest system that just executes all the commands in order, and ending up with the benefits of a conventional build system.

\subsection{Executing commands}
\label{sec:executing_commands}

Given a build script as a list of commands, like in \S\ref{sec:introduction}, the simplest execution model is to run each command sequentially in the order they were given. Importantly, we require that list of commands to be ordered, such that any dependencies are produced before they are used. We consider this sequential execution the reference semantics, and as we develop our design further, require that any optimised/cached implementation gives the same results.

\subsection{Value-dependent commands}
\label{sec:monadic}

While a static list of commands is sufficient for simple builds, it is limited in its expressive power. Taking the build system from \S\ref{sec:introduction}, it would be better to compile and link \emph{all} \texttt{.c} files -- not just those explicitly listed by the script. A more realistic script might be\footnote{We take some liberties with shell scripts around how we replace the extensions, so as not to obscure the main focus.}:

\vspace{3mm}
\begin{verbatim}
FILES=$(ls *.c)
for FILE in $FILES; do
    gcc -c $FILE
done
gcc -o main.exe ${FILES%.c}.o
\end{verbatim}
\vspace{3mm}

\begin{figure}
\begin{verbatim}
import Development.Rattle
import System.FilePath
import System.FilePattern

main = runRattle $ do
    let toO x = takeBaseName x <.> "o"
    cs <- liftIO $ getDirectoryFiles "." [root </> "*.c"]
    forM_ cs $ \c ->
        cmd "gcc -c" c
    cmd "gcc -o main.exe" (map toO cs)
\end{verbatim}
\caption{A Haskell/\Rattle version of the script from \S\ref{sec:monadic}}
\label{fig:monadic}
\end{figure}

This script now has a curious mixture of commands (\texttt{ls}, \texttt{gcc}), control logic (\texttt{for}) and simple manipulation (changing file extension). Importantly, there is \emph{no fixed list of commands} -- the future commands are determined based on the results of previous commands. Concretely, in this example, the result of \texttt{ls} changes which \texttt{gcc} commands are executed. The transition from a fixed list of commands to a dynamic list matches the \texttt{Applicative} vs \texttt{Monadic} destinction of \citet{build_systems_a_la_carte} \S3.5.

To accomodate a dynamic list of commands, we adjust our model so that a build script is a series of commands, where future commands may depend on the results of previous commands in ways that are not visible to the build system. The commands are produced with ``cheap'' functions such as control logic and simple manipulations. We consider the cheap commands to be fixed overhead, run on every build, and not cached or parallelised in any way. If any of these cheap manipulations becomes expensive, they can be replaced by a command, which will then be handled properly. The simple list of commands from \S\ref{sec:executing_commands} is then a degenerate case of no interesting logic.

An important consequence of the control logic not being visible to the build system is that the build system has no prior knowledge of which commands are coming next, or if they have changed. As a result, even if you are using a simple static script such as from \S\ref{sec:introduction}, and then manually edit the script, the build will execute correctly. The build system is unaware if you edited the script, or if the commands were conditional on something that it cannot observe. Therefore, this model solves the problem of self-tracking from \citet{build_systems_a_la_carte} \S6.5.

\subsection{Dependency tracing}
\label{sec:assume_tracing}

For the rest of this section we assume the existence of \emph{dependency tracing} which can, after a command completes, tell us which files that command read and which files it wrote -- we discuss the implementation and limitations of dependency tracing in \S\ref{sec:tracing}. Concretely, we can run a command in a special mode such that when the command completes (and not before) we can determine which files it read and which it wrote. We cannot determine at which point during the execution these files were accessed, or which order they were accessed in. We cannot prevent or otherwise redirect an in-progress access. These limitations are a (frustrating!) consequence of the tracing technology used.

\subsection{Skipping unnecessary commands}
\label{sec:skipping_unnecessary}

When \Rattle runs a command, it uses tracing to capture the files read and written, and then records their hashes after the command finishes. If \Rattle subsequently runs the same command, and the inputs and outputs haven't changed (same hashes), it can be skipped. This approach is the fundamental aspect of \Fabricate\citep{fabricate}. However, this approach has some issues that can result in incorrect builds.  The following are assumptions \Rattle makes about a build to avoid the aforementioned issues.

% SS todo make specific issues more clear

\begin{itemize}
\item \Rattle assumes that each command is atomic - it cannot be subdivided into smaller parts. If a command is secretly two independent commands then they should usually be expressed as such so they can be individually skipped.

\item If a command is deterministic, then running it again will change nothing. However, many commands are not deterministic -- e.g. the output of \texttt{ghc} object files contains random values within it. \Rattle assumes that where such non-determinism exists any possible output is equally valid.

\item If a command incorporates information such as the timestamp, then a cached value will represent the first time the command was run, not the current time. For commands like compilation that embed the timestamp in an object header, the original timestamp is probably fine.  If a command wants to actually get the current time, we suggest it be made part of the control logic (as per \S\ref{sec:monadic}) so it will run everytime the build runs. The same applies to commands that require unique information, e.g. the generation of a GUID or random number.

\item If a command both reads and writes the same file, and the information written is fundamentally influenced by the file that was read, then the command never results in a stable state. As an example, \verb"echo x >> foo.txt" will append the character \texttt{x} every time the command is run. As another example, the GHC package database has additional entries added every time a package is installed, making the output a consequence of the original file\footnote{As a consequence many build systems, including \Bazel and \Rattle, use multiple package databases with only one entry per database}. Equally, there are also commands that read the existing file to avoid rewriting a file that hasn't changed (e.g. \texttt{ghc} generating a \texttt{.hi} file) and commands that can cheaply update an existing file in some circumstances (the Micrsoft C++ linker). \Rattle makes the assumption that if a command both reads and writes to a file that the read does not meaningfully influence the write. Thought of another way, \Rattle can consider the command to be non-deterministic and the previous points apply.

\item If a command reads a file that during a build is modified by something not under the observation of \Rattle (e.g. a human or the untracked control logic), then the command may have seen multiple distinct values of the file, and the final hash will not match what the command saw. Therefore, \Rattle makes the assumption that only \Rattle tracked commands are working on the relevant files during the build. \Rattle can detect such errors by checking the modification time of the read file pre-dates the start of the command execution.
\end{itemize}

In general we assume individual commands are well behaved and meet the above assumptions, and if not, they can be lifted into the control logic.

\subsection{Cloud builds}
\label{sec:cloud_builds}

When skipping an execution \Rattle checks that all files accessed have the same hashes as a previous execution. However, if the files read all match a previous execution, and the corresponding output files have been cached, those output files can be copied over \emph{without} rerunning the command. If that cache is in on a server, you end up with cloud build functionality. Assuming commands that can be cached, whether a command uses a cloud oracle or runs locally is not observable to the rest of the system, so we don't need to consider it for the rest of the system. While this approach works beautifully in theory, in practice it leads to at least three separate problems:

\paragraph{Relative build directories} Often the current directory, or users profile directory, will be accessed by commands. These change either if the user has two working directories, or if they use different machines. We solve this by having a substitution table, replacing values such as the users home directory with \texttt{\$HOME}.

\paragraph{Compound commands} Sometimes a command will produce something that is user specific (not great for caching), but the next step will remove the user specificity (good for caching). To fix that we allow compound commands, by conjoining two commands with \texttt{\&\&}. Sometimes the sole purpose of the second command can be to strip machine-unique data from the first command.

\paragraph{Non-deterministic builds} If a command has non-deterministic output then if a user is temporarily disconnected from the cloud storage, and try and build something, then it will result in a different hash. If the user then reconnects to the cloud all actions depending on that non-deterministic build will fail to get a cache hit. There is one solution in \Rattle, where the hash of an output can be considered to be the hash of its inputs, but this setting is enabled on a per-file basis, and has all the problems of deep-constructive traces from \cite{build_systems_a_la_carte} \S?? and cannot benefit from unchanging outputs.

As a technical note, currently \Rattle uses a shared drive for sharing build artefacts, using tools such as NFS or Samba to provide the internet style ``cloud'' part.

\subsection{Build consistency}
\label{sec:hazards}

For a \Make build system to be stable, it must be the case that after a build, a rebuild will not execute any further commands. It's easy to construct examples of sequences of commands that violate this property, for example:

\begin{verbatim}
echo x >> foo.txt
\end{verbatim}

% SS not very clear in skipping unnecessary that those things listed are ``Restrictions''
% NM tried to make it more obvious. It's actually an example in restrictions

% SS changed resctrictions -> assumption since afaik rattle won't produce an error if someone puts that in their build.

As discussed in \S\ref{sec:skipping_unnecessary}, this command does not meet our assumption that a command which both reads and writes a file should not be meaningfully influenced by the initial read. But we can find other sequences of commands, where each command is fine in isolation, but the conjunction is problematic, for example:

\begin{verbatim}
echo 1 > foo.txt
echo 2 > foo.txt
\end{verbatim}

This program writes \texttt{1} to \texttt{foo.txt}, then writes \texttt{2}. If the commands are re-executed then the first command is invalid by virtue of its output changing, and after the first command has re-run, now the second command is invalid. More generally, if a build writes different values to the same file multiple times, it will not be consistent. But even without writing to the same file twice, it is possible to have an inconsistent build:

\begin{verbatim}
sha1sum foo.txt > bar.txt
sha1sum bar.txt > foo.txt
\end{verbatim}

Here \texttt{sha1sum} takes the SHA1 hash of a file, firstly taking the SHA of \texttt{foo.txt} and storing it in \texttt{bar.txt}, then taking the SHA of \texttt{bar.txt} and storing it in \texttt{foo.txt}. The root of the problem is that the script first reads from \texttt{foo.txt} on the first line, then writes to \texttt{foo.txt} on the second line, meaning that when the script is rerun the read of foo.txt will have to be repeated as its value has changed.

It turns out writing to a file after it has already been either read or written is the only circumstance in which a build, where every individual command is well-formed (as per \S\ref{sec:skipping_unnecessary}), is inconsistent. We define such a build as \emph{hazardous} if it violates one of the following consistency rules:

\begin{description}
\item[write after read] If one command reads from a file, and a subsequent command writes to that file, on a future build, the first command will have to be rerun because its input has changed.  This behavior causes a \emph{read-write hazard}.
\item[write after write] If two commands both write to the same file, on a future build, the first will be rerun (it's output has changed), which is likely to then cause the second to be rerun.  This behavior causes a \emph{write-write hazard}.
\end{description}

Using tracing \Rattle spots hazards and raises errors if they occur. We prove that a build system with deterministic control logic and with no hazards always results in no rebuilds in \S\ref{sec:proof:no_rebuild}. In a build system without hazards there is at most one write to any file, which occurs before any reads of that file. We can therefore prove there are no rebuilds by showing the first command can't rebuild, and proceeding by induction. It is not the case that the presence of hazards guarantees subsequent executions will definitely rebuild, for example if the write doesn't actually change the value, but such a build system is dangerous -- if the write definitely can't change the output, the write should not be present.

\subsection{Parallelism}

Given a script with no hazards when executed sequentially, we can show that any interleaving of those commands that also has no hazards will result in an equivalent output in \S\ref{sec:proof:reorder}. Moreover, any parallel or interleaved execution without hazards will also be equivalent, see \S\ref{sec:proof:parallel}. And even further, if \Rattle executes any additional commands that don't cause hazards, they can be shown not to change the results the normal build produced, see \S\ref{sec:proof:additional}.

As a consequence of the above, we have quite a lot of freedom to schedule the commands, provided they do not cause hazards.  There are two ways \Rattle enables parallelism.

\subsubsection{Explicit Parallelism}

In the Haskell API for \Rattle there is a parallel combinator \texttt{forP}. Replacing \texttt{forM} with \texttt{forP} in Figure \ref{fig:monadic} causes the commands to be given to \Rattle in parallel. As a consequence, they can be executed in parallel. The use of explicit parallelism is convenient when replacing a loop, but harder when expressing that three executables can be built in parallel, but that a single shared object common to all of them must complete before starting, so it is difficult to provide \emph{complete} parallelism annotations.

Interestingly, given complete \emph{dependency} information (e.g. as available to \Make) it is possible to infer complete \emph{parallelism} information, but the difficulty of specifying complete dependnecy information is the attraction of a tracing based approach to build systems.

\subsubsection{Implicit Parallelism}
\label{sec:speculation}

The other source of parallelism is implicit, using speculation. If we can predict what commands are coming up next, and predict that their execution will not cause hazards, then we can speculatively execute them.  Such predictions can be made by simply recording the last known execution and using that information to predict the next execution.  If speculation suggests that running a command would be beneficial there are two possible approaches to take.

Firstly, the command can execute remotely, or in a sandboxed manner - ensuring all writes do \emph{not} end up on the file system, but are recorded to the cloud cache. In such a mode we are filling up the coud cache speculative, with the hope that when the future command does arrive it can be satisfied from the cache. However, running remotely requires syncronising the files across, or using a sycronise on demand approach (CITE Microsoft Remote Execution talk). Running with a sandbox which intercepts writes is not an easily available cross-platform feature, so we have not explored it further.

Alternatively, the command can execute locally, which is what \Rattle does. If the build execution lead to a hazard, and commands were executed speculatively, then it is possible that the hazard is entirely an artefact of speculation.  A simple approach to resolving this is to re-run the build without speculation.  A more nuanced approach is to use the hazard's classification, which can be categorised as per \S\ref{sec:proof:classify_hazard}, to decide whether to raise the error immediately (if the speculation was not at fault) or take alternative measures to resolve the hazard, such as selectively eliminating a subset of commands from speculation, or re-executing specific commands.


% Rattle's requirements:
% deterministic, if reading adn writing same file write does not rely on read; aka no appending,

% So up above in the intro to this section we say that ``we have freedom to schedule commands provided they do not cause hazards''.  But there is the distinct possiblity that they WILL cause hazards,
% so what does Rattle do in that situation?

% Rattle is executing a build and speculatively executing commands and has encountered a hazard, what does it do?
% As we've mentioned previously usually when a hazard occurs Rattle terminates because the build violates Rattle's consistency requirements.  But, we've just added this new thing called ``speuculation''
% which changes that a bit.  If we were speculating commands then it is possible that the build doesn't have a consistency violation and Rattle just made a mistake it needs to correct.

% How does Rattle determine which of the two it is?  Consistency violation or artefact os speculation?
% If both commands were executed from the build script, then its a consistency violation and Rattle should error and terminate
% If at least one of the commands was speculated, then Rattle might be able to recover.

% Ways to recover:  re-run certain commands;
% have a read-write hazard:
% speculatively write then require a read: Read read bad information.... we need to have to read read the correct file so we just restart.... same thing as above about dleeting speculative commands

% require a read then speculatively write: need to undo-write some how.....

% require a read then require a write; error obviously.

% have a write-write hazard:
% speculatively write then require a write: Since the write should not fundamentally be influenced by the read, then the required write should just overwrite whatever the speculative write did and
% its ok.  If they happened in parallel, then obviously re-run the required write, which is i guess what we call re-starting since the script would have passed that point already....

% We can delete all speculation info in this case, or only delete the failed command. Or some other sophisticated algorithm that deletes all commands that refer to a specific file or something.
% require a write then speculatively write: need to re-execute the required write, but since we passed it already, restart script and delete speculative commands...

% speculate write speculate write: Rattle will restart right now and can delete these speculation commands, but if nobody else reads/writes these files do we even care?

% require write /require write: error obviously

% todo: need to prove all of the above produce equivalent outputs...

In the case that speculating caused a hazard, there are potential resolutions \Rattle can take that will still result in a correct build.  The following are situations in which \Rattle speculating command(s) could lead to a hazard.

\begin{description}
\item [Two speculated commands write to the same file]
  Two commands in a build script writing to the same file violates \Rattle's consistency requirement and is a \emph{write-write hazard}.  But, if both commands are speculated and no commands in the build script read or write to this file then this should not affect the output of the build.  These two commands can be deleted from the list of speculative commands though in case the build needs to later be restarted.  In the following example, both speculated commands \emph{cp foo.o baz.o} and \emph{cp bar.o baz.o} write to \emph{baz.o}.  As long as no later command reads or writes to baz.o the outcome of the build will not change and so \Rattle does not need to take any action.
\begin{verbatim}
  cp foo.o baz.o [speculate]
  cp bar.o baz.o [speculate]
  ...
  gcc -o Main foo.o bar.o
\end{verbatim}

\item [A speculated command and a command in build script write to the same file]
  If \Rattle speculated a command which writes to the same file as a command in the build script, then another \emph{write-write hazard} has occurred entirely due to speculation.  Normally a \emph{write-write hazard} indicates that the build script violates \Rattle's consistency requirement, but in this case the violation might not have occurred if \Rattle didn't speculation the offending command.  To recover from this \Rattle can re-execute the build script, and remove the offending command(s) from the speculation list.

  Continuing with the previous example, a \emph{write-write hazard} occurs between \emph{gcc -o baz.c} and both of the \emph{cp} commands.  Rattle can recover from this by re-executing the build and removing both offending \emph{cp} commands from the speculation list.

\begin{verbatim}
  cp foo.o baz.o [speculate]
  cp bar.o baz.o [speculate]
  gcc -o baz.c
  .
  .
  -- re-run build
  gcc -o baz.c [re-execute]
  .
  .
\end{verbatim}

\item [A speculated command writes to a file that a command in build script reads from]
  If \Rattle speculated a command which writes to the same file as a command in the build script reads from, then a \emph{read-write hazard} has occurred entirely due to speculation.  Normally a \emph{read-write hazard} indicated that the build script violates \Rattle's consistency requirement, but in this case the violation might not have occurred if \Rattle didn't speculate the offending command.  To recover from this, \Rattle can re-execute the build script, and remove the offending command from the speculation list.

\begin{verbatim}
gcc -c foo.c
gcc -o Main foo.o bar.o
gcc -o Main foo.o baz.o [speculate]
./Main
-- re-run build
gcc -c foo.c [ don't re-execute because up to date]
gcc -o Main foo.o bar.o [re-execute]
./Main [re-execute]
\end{verbatim}

SS TODO : fix above because it isn't an example of this, actually an example of write-write

% that is actually not an example of this and I can't think of one.

\item [Speculated command reads from a file that another command writes to]
    A \emph{read-write hazard} will occur if a second command executes concurrently with or after the speculated command which read the file.  If these two commands were executed as part of the build script, the hazard would be \emph{non-recoverable} and \Rattle would error and terminate, but because one of them was executed speculatively it is possible there is no consistency violation in the build script.  Because the speculated read executed too soon, it potentially read incorrect data from the file.  To get the speculated read command to read the correct file however, \Rattle can just re-execute the command. For example:

\begin{verbatim}
  cp foo.o baz.o [speculate]
  gcc -c foo.c
  cp foo.o baz.o [re-execute]
\end{verbatim}

In the above example, a \emph{read-write hazard} occurred when \emph{cp foo.o baz.o} ran and then \emph{gcc -c foo.c} ran.  \emph{cp foo.o baz.o} copied the wrong version of \emph{foo.o}, but if \Rattle
runs \emph{cp foo.o baz.o} again after \emph{gcc -c foo.c} has completed, \emph{cp foo.o baz.o} will copy the correct version of \emph{foo.o} and the build can just continue.
\end{description}

A more detailed explanation of hazards and proofs of the above claims follows in section \S\ref{sec:proof:classify_hazard}.

% NM TODO: Write a lot about selectively eliminate a subset of commands from speculation (if speculation was at fault).
